{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: DataFrames with RLM\n",
    "\n",
    "DSPy provides first-class support for pandas DataFrames in the RLM (Recursive Language Model) module. DataFrames are automatically serialized via Parquet format, preserving dtypes, and rich metadata is provided to the LLM.\n",
    "\n",
    "> **Important**: `dspy.DataFrame` should only be used with `dspy.RLM`. Other modules like `ChainOfThought` or `Predict` will only see a string representation of the DataFrame, not the actual data. RLM provides a Python sandbox where the DataFrame is available for code execution.\n",
    "\n",
    "Install the latest DSPy via `pip install -U dspy` and follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "First, let's configure DSPy with an LM and create a sample DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Pydantic serializer warnings\")\n",
    "\n",
    "import dspy\n",
    "import pandas as pd\n",
    "\n",
    "# Configure your LM\n",
    "lm = dspy.LM(\"anthropic/claude-sonnet-4-5-20250929\", max_tokens=16000)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "dataframe = pd.DataFrame({\n",
    "    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    \"age\": [25, 30, 35, 40, 45],\n",
    "    \"city\": [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Miami\"]\n",
    "})\n",
    "\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Using `dspy.DataFrame` in Signatures\n",
    "\n",
    "To use a DataFrame as an input field in a DSPy Signature, use the `dspy.DataFrame` type annotation. This tells Pydantic how to handle the DataFrame type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocWriter(dspy.Signature):\n",
    "    \"\"\"Write documentation for the provided data.\"\"\"\n",
    "    \n",
    "    dataframe: dspy.DataFrame = dspy.InputField()\n",
    "    documentation: str = dspy.OutputField(desc=\"Generated markdown documentation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Running RLM with DataFrames\n",
    "\n",
    "Now we can use `dspy.RLM` to process the DataFrame. The RLM module will:\n",
    "\n",
    "1. Serialize the DataFrame to Parquet format (preserving dtypes)\n",
    "2. Provide rich metadata to the LLM (shape, columns, dtypes, sample rows)\n",
    "3. Make the DataFrame available in the Python sandbox for code execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_writer = dspy.RLM(\n",
    "    DocWriter,\n",
    "    max_iterations=10,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = doc_writer(dataframe=dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) How It Works\n",
    "\n",
    "When you pass a DataFrame to RLM:\n",
    "\n",
    "1. **Serialization**: The DataFrame is serialized to Parquet format using PyArrow, which preserves data types (int, float, datetime, categorical, etc.)\n",
    "\n",
    "2. **Metadata**: The LLM receives rich metadata about the DataFrame:\n",
    "   - Shape (rows x columns)\n",
    "   - Column names and dtypes\n",
    "   - Null value counts\n",
    "   - Sample rows (first and last 3 rows)\n",
    "\n",
    "3. **Sandbox Access**: The DataFrame is made available in the Python sandbox, where the LLM-generated code can access it directly using pandas operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Advanced Example: Data Analysis\n",
    "\n",
    "Let's try a more complex example where the LLM analyzes the data from the UCI Adult / Census Income dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_data = pd.read_csv(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
    "    header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "\n",
    "class DataAnalyst(dspy.Signature):\n",
    "    \"\"\"Analyze the data and provide insights. Do just a very basic analysis, nothing substantial. When generating images, do this using in-memory IO operations and return them as base64-encoded strings.\"\"\"\n",
    "    \n",
    "    input_data: dspy.DataFrame = dspy.InputField()\n",
    "    analysis_title: str = dspy.OutputField()\n",
    "    analysis_summary: str = dspy.OutputField(desc=\"Detailed analysis with statistics and insights.\")\n",
    "    analysis_graphs: List[dspy.Image] = dspy.OutputField(desc=\"A series of graphs or images related to the analysis. These should be encoded as base64 urls.\")\n",
    "\n",
    "analyst = dspy.RLM(DataAnalyst, max_iterations=10, verbose=True)\n",
    "result = analyst(input_data=input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(url=result.analysis_graphs[0].url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Use `dspy.DataFrame` as the type annotation for DataFrame input fields\n",
    "- DataFrames are serialized via Parquet, preserving all dtypes\n",
    "- Rich metadata (shape, columns, dtypes, samples) is provided to the LLM\n",
    "- The DataFrame is available in the RLM sandbox for pandas operations\n",
    "- Works seamlessly with other input types (strings, numbers, etc.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
