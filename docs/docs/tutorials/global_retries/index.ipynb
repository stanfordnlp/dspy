{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7437ca87",
   "metadata": {},
   "source": [
    "# Setting global retry defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33342724",
   "metadata": {},
   "source": [
    "\n",
    "Global retry defaults let you configure transient error handling once and keep behavior consistent across modules. Configure with `dspy.configure(default_num_retries=4, retry_strategy=\"exponential_backoff_retry\")`, override per instance with `dspy.LM(..., num_retries=1)`, or scope a block using `with dspy.context(default_num_retries=6):`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1477680",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "import dspy\n",
    "\n",
    "dspy.configure(default_num_retries=4, retry_strategy=\"exponential_backoff_retry\")\n",
    "\n",
    "lm_default = dspy.LM(model=\"openai/gpt-4o-mini\", cache=False, num_retries=None)\n",
    "print(lm_default.dump_state()[\"num_retries\"])  # 4 retries by default\n",
    "\n",
    "with dspy.context(default_num_retries=6):\n",
    "    lm_scoped = dspy.LM(model=\"openai/gpt-4o-mini\", cache=False, num_retries=None)\n",
    "    print(lm_scoped.dump_state()[\"num_retries\"])  # 6 retries in this scope\n",
    "\n",
    "lm_override = dspy.LM(model=\"openai/gpt-4o-mini\", cache=False, num_retries=1)\n",
    "print(lm_override.dump_state()[\"num_retries\"])  # 1 retry for this instance"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
